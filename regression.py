import tensorflow as tf
import matplotlib.pyplot as plt

x_data = [4.0391, 1.3197, 9.5613, 0.5978, 3.5316, 0.1540, 1.6899, 7.3172, 4.5092, 2.9632]
y_data = [11.4215, 10.0112, 30.2991, 1.0625, 13.1776, -3.1976, 6.7367, 23.8550, 14.8951, 11.6137]


W = tf.Variable(tf.random_uniform([1], -5.0, 5.0))
b = tf.Variable(tf.random_uniform([1], -5.0, 5.0))

X = tf.placeholder(tf.float32)
Y = tf.placeholder(tf.float32)

hypothesis = W * X + b

cost = tf.reduce_mean(tf.square(hypothesis - Y))

learning_rate = 0.01
optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
train = optimizer.minimize(cost)

with tf.Session() as sess :
    sess.run(tf.global_variables_initializer())

    for step in range(2001):
        sess.run(train, feed_dict={X:x_data, Y:y_data})
        if step % 20 == 0:
            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W), sess.run(b))

    answer = sess.run(hypothesis, feed_dict={X:5})
    print('When X=5, hypothesis = ' + str(answer))

    plt.figure(1)
    plt.title('Linear Regression')
    plt.xlabel('x')
    plt.ylabel('y')
    # 주어진 데이터들을 점으로 표시
    plt.plot(x_data, y_data, 'ro')
    # 예측한 일차함수를 직선으로 표시
    plt.plot(x_data, sess.run(W) * x_data + sess.run(b), 'b')
    # X=5 일때의 계산 값
    plt.plot([5], answer, 'go')
    plt.show()